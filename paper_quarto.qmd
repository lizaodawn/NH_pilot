---
title: "Keyword and Collocation analysis on India-related text of Natural History"
format: html
---

```{r setup, include=FALSE}
library('tidyverse')
library('mclm')
library('here')
library('kableExtra')
library('dplyr')
library('ggplot2')
library('leaflet')
```

# 1. Research Question

Natural History by Pliny the Elder is considered the very first encyclopedia in modern history. It not only showcased the actual merchant exchange of the Roman Empire, but also manifested the spatial imagination of Pliny the Elder and the referenced scholarships of that time.

```{r}
#| label: table
#| warning: false
data <- read.csv("geotext_whole.csv")

summary_data <- data %>%
  group_by(ToposText_ID, Place_Name, Lat, Long) %>%
  summarise(Count = n()) %>%
  arrange(desc(Count)) %>%
  ungroup()

top_20_summary_data <- summary_data %>%
  top_n(20, Count) %>%
  ungroup() %>% print()

```

```{r}
#| label: barchart
#| warning: false
ggplot(top_20_summary_data, aes(x = reorder(Place_Name, -Count), y = Count)) +
  geom_bar(stat = "identity") +
  labs(x = "Place Name", y = "Count") +
  ggtitle("Top 20 Place Names Mentioned") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
#| label: map
#| warning: false
m <- leaflet() %>%
  addTiles() %>%
  addCircleMarkers(
    data = top_20_summary_data,
    lat = ~Lat,
    lng = ~Long,
    radius = sqrt(top_20_summary_data$Count) * 0.8,  # Adjust the scaling factor as needed
    color = "blue",
    fill = TRUE,
    fillOpacity = 0.6,
    popup = paste("Place Name:", top_20_summary_data$Place_Name, "<br>",
                  "Count:", top_20_summary_data$Count)
  ) %>% print()

```

# 2. Corpus Description

As there is a digitized and name entities annotated full text available on [ToposText project](https://topostext.org/work/148 "Check Natural History on ToposText"), I scraped the full text and exported them in .txt as a corpus, and also exported those with geographical location annotations, which considered as geographically related texts as a sub corpus.

(statistics)

# 3. Data Preparation

```{r}
#| label: corpus
#| warning: false

corpus_folder <- here("NH_wholetext")
fnames_wholetext <- get_fnames(corpus_folder) %>% 
  keep_re("[.]txt")

print(fnames_wholetext, 10, hide_path = corpus_folder)

corpus_folder <-  here("NH_geotext_india")
fnames_indiatext <- get_fnames(corpus_folder) %>% 
  keep_re("[.]txt")

print(fnames_indiatext, 10, hide_path = corpus_folder)
```

# 4. Keyword Analysis on India-related texts

```{r}
#| label: keyword
#| warning: false

# build frequency list for target corpus
flist_target <- fnames_indiatext %>%
  freqlist(
    re_token_splitter = r"--[(?xi)    \s+   ]--", # whitespace as token splitter
    re_token_transf_in = "[[:punct:]]", # Match punctuation marks
    token_transf_out = "" # Replace punctuation marks with an empty string
  )

# build frequency list for reference corpus
flist_ref <- fnames_wholetext %>%
  freqlist(re_token_splitter = r"--[(?xi)    \s+   ]--", # whitespace as token splitter
           re_token_transf_in = "[[:punct:]]", # Match punctuation marks
           token_transf_out = "") 

# calculate scores
scores_kw <- assoc_scores(flist_target, flist_ref)

top_scores_kw <- scores_kw %>% 
  filter(PMI >= 2 & G_signed >= 2)

# print top_scores_kw, sorted by PMI
top_scores_kw %>%
  print(sort_order = "PMI")

# print top_scores_kw, sorted by G_signed
top_scores_kw %>%
  print(sort_order = "G_signed")
```

```{r}
#| label: top30keyword
#| warning: false

top_scores_kw %>% # also valid for top_scores_colloc
  as_tibble() %>%
  select(type, a, PMI, G_signed) %>% # select 4 columns
  arrange(desc(PMI)) %>%             # sort by PMI (descending) 
  head(30) %>%                       # select top 30 rows
  kbl(col.names = c("Type", "Frequency", "PMI", r"(Signed $G^2$)")) %>% 
  kable_minimal() %>% 
  scroll_box(height = "400px")
```

# 5. Collocation Analysis on "India" in the whole corpus

```{r}
#| label: collocation
#| warning: false

coocs <- fnames_wholetext %>% 
  surf_cooc("(?xi)  ^ india $", 
            re_token_splitter = r"--[(?xi)    \s+   ]--", # whitespace as token splitter
            re_token_transf_in = "[[:punct:]]", # Match punctuation marks
            token_transf_out = "")
coocs$target_freqlist
coocs$ref_freqlist

# calculate scores
scores_colloc <- assoc_scores(coocs)

top_scores_colloc <- scores_colloc %>% 
  filter(PMI >= 2 & G_signed >= 2)

# print top_scores_colloc, sorted by PMI
top_scores_colloc %>%
  print(sort_order = "PMI")

# print top_scores_colloc, sorted by G_signed
top_scores_colloc %>%
  print(sort_order = "G_signed")
```

```{r}
#| label: top30collocatioin
#| warning: false
top_scores_colloc %>% # also valid for top_scores_kw
  as_tibble() %>%
  select(type, a, PMI, G_signed) %>% # select 4 columns
  arrange(desc(G_signed)) %>%        # sort by G_signed (descending)  
  head(30) %>%                       # select top 30 rows
  kbl(col.names = c("Type", "Frequency", "PMI", r"(Signed $G^2$)")) %>% 
  kable_minimal() %>% 
  scroll_box(height = "400px")
```

# 6. Conclusion

Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see <https://quarto.org>.
